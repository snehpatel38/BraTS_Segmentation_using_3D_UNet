<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>BraTS Segmentation Using 3D U-Net</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f4f4f4;
      margin: 0;
      padding: 20px;
      max-width: 900px;
      margin: auto;
      color: #333;
    }
    h1, h2, h3 {
      text-align: center;
      color: #222;
    }
    p, li {
      line-height: 1.6;
    }
    a {
      color: #0056b3;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    img {
      max-width: 100%;
      margin: 15px auto;
      display: block;
      border: 1px solid #ccc;
      border-radius: 4px;
    }
    code {
      background-color: #eee;
      padding: 2px 4px;
      border-radius: 4px;
      font-size: 90%;
    }
    ul {
      padding-left: 20px;
      margin-bottom: 20px;
    }
    section {
      background: #fff;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 0 10px rgba(0,0,0,0.05);
      margin-bottom: 30px;
    }
    footer {
      text-align: center;
      font-size: 14px;
      color: #777;
      margin-top: 40px;
    }
  </style>
</head>
<body>

  <h1>BraTS Segmentation Using 3D U-Net</h1>
  <p style="text-align: center;">
    üîó <a href="https://github.com/snehpatel38/BraTS_segmentation_Using_3D_UNet" target="_blank">
    View Full Project on GitHub</a>
  </p>

  <section>
    <h2>üìÅ Dataset Info</h2>
    <p>
      The dataset used is the <strong>BraTS 2020 multimodal brain tumor segmentation dataset</strong>, available on Kaggle:
      <br>
      <a href="https://www.kaggle.com/datasets/awsaf49/brats20-dataset-training-validation" target="_blank">
        https://www.kaggle.com/datasets/awsaf49/brats20-dataset-training-validation
      </a>
    </p>
    <ul>
      <li>All scans are in <code>.nii.gz</code> (NIfTI) format.</li>
      <li>Each sample includes 4 MRI modalities:
        <ul>
          <li><strong>T1</strong>: Native</li>
          <li><strong>T1CE</strong>: Post-contrast T1-weighted</li>
          <li><strong>T2</strong>: T2-weighted</li>
          <li><strong>FLAIR</strong>: Fluid Attenuated Inversion Recovery</li>
        </ul>
      </li>
      <li>Ground truth labels:
        <ul>
          <li><code>0</code>: Background</li>
          <li><code>1</code>: Necrotic/Non-enhancing tumor core (NCR/NET)</li>
          <li><code>2</code>: Peritumoral edema (ED)</li>
          <li><code>4</code>: GD-enhancing tumor (ET)</li>
        </ul>
      </li>
    </ul>
  </section>

  <section>
    <h2>‚öôÔ∏è Tools & Libraries Used</h2>
    <ul>
      <li><code>numpy</code></li>
      <li><code>nibabel</code></li>
      <li><code>glob</code></li>
      <li><code>matplotlib</code></li>
      <li><code>tensorflow</code> and <code>keras</code></li>
      <li><code>sklearn.preprocessing.MinMaxScaler</code></li>
    </ul>
  </section>

  <section>
    <h2>üß† Segmentation Pipeline</h2>
    <ol>
      <li>
        <strong>Step 1: Data Preparation</strong>
        <ul>
          <li>Loaded MRI modalities using <code>nibabel</code></li>
          <li>Normalized volume values using <code>MinMaxScaler</code></li>
          <li>Cropped original shape <code>240√ó240√ó155</code> to <code>128√ó128√ó128</code> for uniform training</li>
          <li>Filtered out samples where tumor covered &lt; 1% of the brain volume</li>
          <li>Split data into 75% training and 25% validation using <code>splitfolders</code></li>
        </ul>
      </li>
      <li>
        <strong>Step 2: Custom Data Generator</strong>
        <ul>
          <li>Keras' <code>ImageDataGenerator</code> doesn't support <code>.npy</code> files</li>
          <li>Created a generator that:
            <ul>
              <li>Loads preprocessed data from disk</li>
              <li>Applies shuffling and batch generation</li>
              <li>Returns 3D MRI volume and corresponding mask</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <strong>Step 3: Define the 3D U-Net Model</strong>
        <ul>
          <li>Extended standard 2D U-Net to 3D using:
            <ul>
              <li><code>Conv3D</code>, <code>MaxPooling3D</code>, and <code>UpSampling3D</code></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <strong>Step 4: Training and Prediction</strong>
        <ul>
          <li>Trained using the custom data generator</li>
          <li>Used Dice coefficient and Categorical Focal Loss</li>
          <li>Visualized predictions using <code>matplotlib</code> (random 2D slices)</li>
        </ul>
      </li>
    </ol>
  </section>

  <section>
    <h2>üìä Results : 6GB rtx 3050 - 10 Epochs</h2>
    <h3>Training Loss</h3>
    <img src="https://raw.githubusercontent.com/snehpatel38/BraTS_segmentation_Using_3D_UNet/main/result/training.png" alt="Dice Loss Graph">
    <h3>Mean IoU: 61.34 (10 Epochs)</h3>

    <h3>Prediction Samples</h3>
    <img src="https://raw.githubusercontent.com/snehpatel38/BraTS_segmentation_Using_3D_UNet/main/result/pred_1.png" alt="Predicted Tumor">
    <img src="https://raw.githubusercontent.com/snehpatel38/BraTS_segmentation_Using_3D_UNet/main/result/pred_2.png" alt="Predicted Tumor 2">

    <h3>Training vs Validation Loss</h3>
    <img src="https://raw.githubusercontent.com/snehpatel38/BraTS_segmentation_Using_3D_UNet/main/result/train_vs_val_loss.png" alt="Loss Comparison">

    <h3>Training vs Validation Accuracy</h3>
    <img src="https://raw.githubusercontent.com/snehpatel38/BraTS_segmentation_Using_3D_UNet/main/result/train_vs_val_accuracy.png" alt="Accuracy Comparison">
  </section>

  <section>
    <h2>üìå Future Improvements</h2>
    <ul>
      <li>Training the model for more epochs could further improve segmentation accuracy and stability.</li>
      <li>Experimenting with advanced loss functions such as Dice + Focal Loss or Tversky Loss may enhance performance on complex tumor structures.</li>
      <li>Currently, only the training set (~30 GB) was used and split into training and validation. Future work can utilize the full BraTS dataset (including the validation and testing sets) for more robust training and evaluation.</li>
    </ul>
  </section>


  <footer>
    Created by Sneh Patel | <a href="https://github.com/snehpatel38" target="_blank">Visit GitHub Profile</a>
  </footer>

</body>
</html>
