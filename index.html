<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>BraTS Segmentation Using 3D UNet</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      background-color: #f9f9f9;
      color: #333;
    }
    h1, h2 {
      text-align: center;
    }
    img {
      max-width: 100%;
      display: block;
      margin: 15px auto;
      border: 1px solid #ccc;
    }
    ol {
      padding-left: 20px;
    }
    a {
      color: #0066cc;
      text-decoration: none;
    }
    footer {
      text-align: center;
      margin-top: 40px;
      font-size: 14px;
      color: #777;
    }
  </style>
</head>
<body>

  <h1>BraTS Segmentation Using 3D UNet</h1>
  <p style="text-align: center;">
    <a href="https://github.com/snehpatel38/BraTS_segmentation_Using_3D_UNet" target="_blank">View Project on GitHub</a>
  </p>

  <h2>ðŸ§  Procedure</h2>
  <ol>
  <li><strong>Data Loading:</strong> Loaded multimodal BraTS MRI scans (FLAIR, T1ce, T2) using <code>nibabel</code> from:
    <br><code>BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/</code></li>

  <li><strong>Preprocessing:</strong> Normalized MRI volumes with <code>MinMaxScaler</code>, and converted segmentation masks (reassigned label 4 â†’ 3).</li>

  <li><strong>Volume Cropping:</strong> Cropped all 3D images to shape <code>128Ã—128Ã—128</code> for efficient patch training.
    <br>Saved output as <code>.npy</code> files into:
    <br><code>BraTS2020_TrainingData/input_data_3channels/images/</code>
    <br><code>BraTS2020_TrainingData/input_data_3channels/masks/</code></li>

  <li><strong>Volume Filtering:</strong> Skipped volumes where the tumor occupied &lt; 1% of the total mask volume.</li>

  <li><strong>Train/Validation Split:</strong> Used <code>splitfolders</code> to split data into 75% training and 25% validation.
    <br>Output saved in:
    <br><code>BraTS2020_TrainingData/input_data_128/</code></li>

  <li><strong>Step 2: Define Custom Data Generator</strong><br>
    Keras' default <code>ImageDataGenerator</code> does not support <code>.npy</code> files.
    <br>Implemented a custom Python generator that:
    <ul>
      <li>Loads 3D MRI volumes and masks from disk</li>
      <li>Applies shuffling and batching</li>
      <li>Yields (X, y) batches for training</li>
    </ul>
  </li>

  <li><strong>Step 3: Define the 3D U-Net Model</strong><br>
    Approaches used:
    <ul>
      <li>Extend 2D U-Net into 3D using <code>Conv3D</code>, <code>MaxPooling3D</code>, and <code>UpSampling3D</code></li>
      <li>OR use available open-source 3D segmentation models</li>
    </ul>
  </li>

  <li><strong>Step 4: Train and Predict</strong><br>
    <ul>
      <li>Trained the model using batches from the custom data generator</li>
      <li>Evaluated Dice score and loss</li>
      <li>Visualized predictions using <code>matplotlib</code> for random 2D slices</li>
    </ul>
  </li>
</ol>


  <h2>ðŸ“Š Results & Graphs</h2>

  <h3>Training</h3>
  <img src="https://raw.githubusercontent.com/snehpatel38/BraTS_segmentation_Using_3D_UNet/main/result/training.png" alt="Dice Loss Graph">

  <h3>Predicted Tumor Segmentation</h3>
  <img src="https://raw.githubusercontent.com/snehpatel38/BraTS_segmentation_Using_3D_UNet/main/result/pred_1.png" alt="Tumor Segmentation Output">
  <img src="https://raw.githubusercontent.com/snehpatel38/BraTS_segmentation_Using_3D_UNet/main/result/pred_2.png" alt="Tumor Segmentation Output">

  <footer>
    Created by Sneh Patel | <a href="https://github.com/snehpatel38">GitHub Profile</a>
  </footer>

</body>
</html>
